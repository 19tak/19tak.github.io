I"ë<h1 id="ë¬¸ì œ">ë¬¸ì œ</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.datasets import fetch_20newsgroups

news_data = fetch_20newsgroups(subset='all',random_state=156)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(news_data.keys())
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768709-2415fd30-97ef-4dbb-9836-6815c0a5cec0.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd

print('target í´ë˜ìŠ¤ì˜ ê°’ê³¼ ë¶„í¬ë„ \n',pd.Series(news_data.target).value_counts().sort_index())
print('target í´ë˜ìŠ¤ì˜ ì´ë¦„ë“¤ \n',news_data.target_names)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768744-01f2890e-9f76-40b2-9477-64352463e5e2.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(news_data.data[0])
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768776-678b8ee3-b69e-4dd4-a67a-6516c2e622b9.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.datasets import fetch_20newsgroups

# subset='train'ìœ¼ë¡œ í•™ìŠµìš©(Train) ë°ì´í„°ë§Œ ì¶”ì¶œ, remove=('headers', 'footers', 'quotes')ë¡œ ë‚´ìš©ë§Œ ì¶”ì¶œ
train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)
X_train = train_news.data
y_train = train_news.target
print(type(X_train))

# subset='test'ìœ¼ë¡œ í…ŒìŠ¤íŠ¸(Test) ë°ì´í„°ë§Œ ì¶”ì¶œ, remove=('headers', 'footers', 'quotes')ë¡œ ë‚´ìš©ë§Œ ì¶”ì¶œ
test_news= fetch_20newsgroups(subset='test',remove=('headers', 'footers','quotes'),random_state=156)
X_test = test_news.data
y_test = test_news.target
print('í•™ìŠµ ë°ì´í„° í¬ê¸° {0} , í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸° {1}'.format(len(train_news.data) , len(test_news.data)))
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768816-177d8b9f-bc03-4a52-8de0-12747a565f2f.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_extraction.text import CountVectorizer

# Count Vectorizationìœ¼ë¡œ feature extraction ë³€í™˜ ìˆ˜í–‰. 
cnt_vect = CountVectorizer()
cnt_vect.fit(X_train , y_train)
X_train_cnt_vect = cnt_vect.transform(X_train)

# í•™ìŠµ ë°ì´í„°ë¡œ fit( )ëœ CountVectorizerë¥¼ ì´ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ feature extraction ë³€í™˜ ìˆ˜í–‰. 
X_test_cnt_vect = cnt_vect.transform(X_test)

print('í•™ìŠµ ë°ì´í„° Textì˜ CountVectorizer Shape:',X_train_cnt_vect.shape)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768847-6eb7fcda-9144-47c6-bfbe-42530b76b5f6.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# LogisticRegressionì„ ì´ìš©í•˜ì—¬ í•™ìŠµ/ì˜ˆì¸¡/í‰ê°€ ìˆ˜í–‰. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train_cnt_vect , y_train)
pred = lr_clf.predict(X_test_cnt_vect)
print('CountVectorized Logistic Regression ì˜ ì˜ˆì¸¡ ì •í™•ë„ëŠ” {0:.3f}'.format(accuracy_score(y_test,pred)))
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768876-7b354f66-cb1e-4085-afe8-912f6bae7632.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_extraction.text import TfidfVectorizer

# TF-IDF Vectorization ì ìš©í•˜ì—¬ í•™ìŠµ ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…‹ ë³€í™˜. 
tfidf_vect = TfidfVectorizer()
tfidf_vect.fit(X_train)
X_train_tfidf_vect = tfidf_vect.transform(X_train)
X_test_tfidf_vect = tfidf_vect.transform(X_test)

# LogisticRegressionì„ ì´ìš©í•˜ì—¬ í•™ìŠµ/ì˜ˆì¸¡/í‰ê°€ ìˆ˜í–‰. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train_tfidf_vect , y_train)
pred = lr_clf.predict(X_test_tfidf_vect)
print('TF-IDF Logistic Regression ì˜ ì˜ˆì¸¡ ì •í™•ë„ëŠ” {0:.3f}'.format(accuracy_score(y_test ,pred)))
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768915-8c9fdd06-277b-46f4-84e0-ce56a2729caf.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># stop words í•„í„°ë§ì„ ì¶”ê°€í•˜ê³  ngramì„ ê¸°ë³¸(1,1)ì—ì„œ (1,2)ë¡œ ë³€ê²½í•˜ì—¬ Feature Vectorization ì ìš©.
tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300 )
tfidf_vect.fit(X_train)
X_train_tfidf_vect = tfidf_vect.transform(X_train)
X_test_tfidf_vect = tfidf_vect.transform(X_test)

lr_clf = LogisticRegression()
lr_clf.fit(X_train_tfidf_vect , y_train)
pred = lr_clf.predict(X_test_tfidf_vect)
print('TF-IDF Vectorized Logistic Regression ì˜ ì˜ˆì¸¡ ì •í™•ë„ëŠ” {0:.3f}'.format(accuracy_score(y_test ,pred)))
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768956-512a7144-ba16-475e-89b5-0930e3845bba.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.model_selection import GridSearchCV

# ìµœì  C ê°’ ë„ì¶œ íŠœë‹ ìˆ˜í–‰. CVëŠ” 3 Foldì…‹ìœ¼ë¡œ ì„¤ì •. 
params = { 'C':[0.01, 0.1, 1, 5, 10]}
grid_cv_lr = GridSearchCV(lr_clf ,param_grid=params , cv=3 , scoring='accuracy' , verbose=1 )
grid_cv_lr.fit(X_train_tfidf_vect , y_train)
print('Logistic Regression best C parameter :',grid_cv_lr.best_params_ )

# ìµœì  C ê°’ìœ¼ë¡œ í•™ìŠµëœ grid_cvë¡œ ì˜ˆì¸¡ ìˆ˜í–‰í•˜ê³  ì •í™•ë„ í‰ê°€. 
pred = grid_cv_lr.predict(X_test_tfidf_vect)
print('TF-IDF Vectorized Logistic Regression ì˜ ì˜ˆì¸¡ ì •í™•ë„ëŠ” {0:.3f}'.format(accuracy_score(y_test ,pred)))
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126769004-276d92f9-c70f-4ad8-bf82-207233bc5da7.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>
:ET