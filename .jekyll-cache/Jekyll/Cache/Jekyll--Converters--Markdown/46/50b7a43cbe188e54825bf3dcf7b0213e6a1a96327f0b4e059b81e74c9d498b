I"ı
<h1 id="ë¬¸ì œ">ë¬¸ì œ</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd

train_df = pd.read_csv('ratings_train.txt', sep='\t')
train_df.head(3)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126769532-0ec068d4-e9b6-4b5f-88ce-ee901099be31.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train_df['label'].value_counts( )
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126769572-a77e3595-b950-4468-a499-e33bb6163823.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import re

train_df = train_df.fillna(' ')
# ì •ê·œ í‘œí˜„ì‹ì„ ì´ìš©í•˜ì—¬ ìˆ«ìë¥¼ ê³µë°±ìœ¼ë¡œ ë³€ê²½(ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ \d ëŠ” ìˆ«ìë¥¼ ì˜ë¯¸í•¨.) 
train_df['document'] = train_df['document'].apply( lambda x : re.sub(r"\d+", " ", x) )

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…‹ì„ ë¡œë”©í•˜ê³  ë™ì¼í•˜ê²Œ Null ë° ìˆ«ìë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜
test_df = pd.read_csv('ratings_test.txt', sep='\t')
test_df = test_df.fillna(' ')
test_df['document'] = test_df['document'].apply( lambda x : re.sub(r"\d+", " ", x) )
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from konlpy.tag import Twitter

twitter = Twitter()
def tw_tokenizer(text):
    # ì…ë ¥ ì¸ìë¡œ ë“¤ì–´ì˜¨ text ë¥¼ í˜•íƒœì†Œ ë‹¨ì–´ë¡œ í† í°í™” í•˜ì—¬ list ê°ì²´ ë°˜í™˜
    tokens_ko = twitter.morphs(text)
    return tokens_ko
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Twitter ê°ì²´ì˜ morphs( ) ê°ì²´ë¥¼ ì´ìš©í•œ tokenizerë¥¼ ì‚¬ìš©. ngram_rangeëŠ” (1,2) 
tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)
tfidf_vect.fit(train_df['document'])
tfidf_matrix_train = tfidf_vect.transform(train_df['document'])
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Logistic Regression ì„ ì´ìš©í•˜ì—¬ ê°ì„± ë¶„ì„ Classification ìˆ˜í–‰. 
lg_clf = LogisticRegression(random_state=0)

# Parameter C ìµœì í™”ë¥¼ ìœ„í•´ GridSearchCV ë¥¼ ì´ìš©. 
params = { 'C': [1 ,3.5, 4.5, 5.5, 10 ] }
grid_cv = GridSearchCV(lg_clf , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )
grid_cv.fit(tfidf_matrix_train , train_df['label'] )
print(grid_cv.best_params_ , round(grid_cv.best_score_,4))
</code></pre></div></div>
:ET