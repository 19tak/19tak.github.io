I"í<h1 id="ë¬¸ì œ">ë¬¸ì œ</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.datasets import fetch_20newsgroups

news_data = fetch_20newsgroups(subset='all',random_state=156)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(news_data.keys())
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768709-2415fd30-97ef-4dbb-9836-6815c0a5cec0.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd

print('target í´ë˜ìŠ¤ì˜ ê°’ê³¼ ë¶„í¬ë„ \n',pd.Series(news_data.target).value_counts().sort_index())
print('target í´ë˜ìŠ¤ì˜ ì´ë¦„ë“¤ \n',news_data.target_names)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768744-01f2890e-9f76-40b2-9477-64352463e5e2.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(news_data.data[0])
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768776-678b8ee3-b69e-4dd4-a67a-6516c2e622b9.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.datasets import fetch_20newsgroups

# subset='train'ìœ¼ë¡œ í•™ìŠµìš©(Train) ë°ì´í„°ë§Œ ì¶”ì¶œ, remove=('headers', 'footers', 'quotes')ë¡œ ë‚´ìš©ë§Œ ì¶”ì¶œ
train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)
X_train = train_news.data
y_train = train_news.target
print(type(X_train))

# subset='test'ìœ¼ë¡œ í…ŒìŠ¤íŠ¸(Test) ë°ì´í„°ë§Œ ì¶”ì¶œ, remove=('headers', 'footers', 'quotes')ë¡œ ë‚´ìš©ë§Œ ì¶”ì¶œ
test_news= fetch_20newsgroups(subset='test',remove=('headers', 'footers','quotes'),random_state=156)
X_test = test_news.data
y_test = test_news.target
print('í•™ìŠµ ë°ì´í„° í¬ê¸° {0} , í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸° {1}'.format(len(train_news.data) , len(test_news.data)))
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768816-177d8b9f-bc03-4a52-8de0-12747a565f2f.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_extraction.text import CountVectorizer

# Count Vectorizationìœ¼ë¡œ feature extraction ë³€í™˜ ìˆ˜í–‰. 
cnt_vect = CountVectorizer()
cnt_vect.fit(X_train , y_train)
X_train_cnt_vect = cnt_vect.transform(X_train)

# í•™ìŠµ ë°ì´í„°ë¡œ fit( )ëœ CountVectorizerë¥¼ ì´ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ feature extraction ë³€í™˜ ìˆ˜í–‰. 
X_test_cnt_vect = cnt_vect.transform(X_test)

print('í•™ìŠµ ë°ì´í„° Textì˜ CountVectorizer Shape:',X_train_cnt_vect.shape)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768847-6eb7fcda-9144-47c6-bfbe-42530b76b5f6.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# LogisticRegressionì„ ì´ìš©í•˜ì—¬ í•™ìŠµ/ì˜ˆì¸¡/í‰ê°€ ìˆ˜í–‰. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train_cnt_vect , y_train)
pred = lr_clf.predict(X_test_cnt_vect)
print('CountVectorized Logistic Regression ì˜ ì˜ˆì¸¡ ì •í™•ë„ëŠ” {0:.3f}'.format(accuracy_score(y_test,pred)))
</code></pre></div></div>
:ET