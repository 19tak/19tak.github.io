I"¢$<h1 id="ë¬¸ì œ">ë¬¸ì œ</h1>

<p>ê·¸ë™ì•ˆ ì½ì–´ì˜¤ë˜ csv íŒŒì¼ê³¼ëŠ” ë‹¤ë¥´ê²Œ í•´ë‹¹ data setì€ ë§ì€ ìˆ˜ì˜ featureì™€ ë°ì´í„°ë“¤ë¡œ ì´ë£¨ì–´ì ¸ì„œ íŒŒì¼ì´ ë‚˜ë‰˜ì–´ì ¸ìˆë‹¤.</p>

<p>â€‹features.txt ì—ëŠ” ì¤‘ë³µì„ í¬í•¨í•œ 561ê°œì˜ featureì— ëŒ€í•œ indexì™€ nameì´
_text.tx, _train.txt ì—ëŠ” ê° featureì— ëŒ€í•œ dataë“¤ì˜ test, train splitì´ ë‹´ê²¨ì ¸ìˆë‹¤.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

# features.txt íŒŒì¼ì—ëŠ” í”¼ì²˜ ì´ë¦„ indexì™€ í”¼ì²˜ëª…ì´ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ìˆìŒ. ì´ë¥¼ DataFrameìœ¼ë¡œ ë¡œë“œ.
feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\s+',
                        header=None,names=['column_index','column_name'])

# í”¼ì²˜ëª… indexë¥¼ ì œê±°í•˜ê³ , í”¼ì²˜ëª…ë§Œ ë¦¬ìŠ¤íŠ¸ ê°ì²´ë¡œ ìƒì„±í•œ ë’¤ ìƒ˜í”Œë¡œ 10ê°œë§Œ ì¶”ì¶œ
feature_name = feature_name_df.iloc[:, 1].values.tolist()
print('ì „ì²´ í”¼ì²˜ëª…ì—ì„œ 10ê°œë§Œ ì¶”ì¶œ:', feature_name[:10])
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767492-c04d488e-e2a8-4844-bf71-23afefa70a85.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>feature_dup_df = feature_name_df.groupby('column_name').count()
feature_name_df.groupby('column_name').count()
print(feature_dup_df[feature_dup_df['column_index']&gt;1].count())
feature_dup_df[feature_dup_df['column_index']&gt;1].head()
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767570-c87988f7-999b-4dad-9da7-ebe30a0aea20.png" alt="image" />
<img src="https://user-images.githubusercontent.com/84369912/126767591-4396e768-3f70-462f-abc1-cd6cdba34a5d.png" alt="image" /></p>

<p>ì¤‘ë³µëœ feature nameì„ í”¼í•˜ëŠ” ê²ƒì„ ì›ì¹™ìœ¼ë¡œ í•˜ê¸° ë•Œë¬¸ì— ì¤‘ë³µëœ feature nameë“¤ì„ í™•ì¸í•´ì£¼ì—ˆë‹¤.</p>

<p>ì¤‘ë³µëœ ì›ë³¸ feature name ë’¤ì— _1 ë˜ëŠ” _2ë¥¼ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µì„ í”¼í•´ì£¼ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_new_feature_name_df(old_feature_name_df):
    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),
                                 columns=['dup_cnt'])
    feature_dup_df = feature_dup_df.reset_index()
    new_feature_dup_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')
    new_feature_dup_df['column_name'] = new_feature_dup_df[['column_name',
                                                            'dup_cnt']].apply(lambda x: x[0]+'_'+
                                                                             str(x[1])
                                                                             if x[1]&gt;0
                                                                             else x[0], axis=1)
    new_feature_dup_df = new_feature_dup_df.drop(['index'],axis=1)
    return new_feature_dup_df
</code></pre></div></div>
<p>ì¤‘ë³µëœ feature nameì„ ì²˜ë¦¬í•´ì£¼ê³  test, train split ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•œë‹¤.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_human_dataset():
    
    # ê° ë°ì´í„° íŒŒì¼ì€ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬, read_csvì—ì„œ ê³µë°± ë¬¸ìë¥¼ sepìœ¼ë¡œ í• ë‹¹
    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\s+',
                             header=None, names=['column_index','column_name'])
    
    # ì¤‘ë³µëœ í”¼ì³ëª…ì„ ìˆ˜ì •í•˜ëŠ” get_new_feature_name_df()ë¥¼ ì´ìš©, ì‹ ê·œ í”¼ì²˜ëª… DataFrame ìƒì„±
    new_feature_name_df = get_new_feature_name_df(feature_name_df)
    
    # DataFrameì— í”¼ì²˜ëª…ì„ ì¹¼ëŸ¼ìœ¼ë¡œ ë¶€ì—¬í•˜ê¸° ìœ„í•´ ë¦¬ìŠ¤íŠ¸ ê°ì²´ë¡œ ë‹¤ì‹œ ë³€í™˜
    feature_name = new_feature_name_df.iloc[:,1].values.tolist()
    
    # í•™ìŠµ í”¼ì²˜ ë°ì´í„°ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ í”¼ì²˜ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë¡œë”©. ì¹¼ëŸ¼ëª…ì€ feature_name ì ìš©
    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\s+',names=feature_name)
    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\s+',names=feature_name)
    
    # í•™ìŠµ ë ˆì´ë¸”ê³¼ í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë¡œë”©í•˜ê³  ì¹¼ëŸ¼ëª…ì€ actionìœ¼ë¡œ ë¶€ì—¬
    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\s+',header=None,names=['action'])
    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\s+',header=None,names=['action'])
    
    # ë¡œë“œëœ í•™ìŠµ/í…ŒìŠ¤íŠ¸ìš© DataFrameì„ ëª¨ë‘ ë°˜í™˜
    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = get_human_dataset()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print('## í•™ìŠµ í”¼ì²˜ ë°ì´í„°ì…‹ info()')
print(X_train.info())
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767718-7810d623-005d-4873-9a97-d476e450127c.png" alt="image" /></p>

<p>ë¡œë“œëœ í•™ìŠµìš© í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(y_train['action'].value_counts())
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767755-0ca66017-ea1c-4159-b498-c24e33fee585.png" alt="image" /></p>

<p>ë¡œë“œëœ í•™ìŠµìš© ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ì—ì„œ ìˆ«ìí˜•ì˜ ë ˆì´ë¸” í™•ì¸ ë³„ë„ì˜ ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© ë¶ˆí•„ìš”</p>

<h1 id="decision-tree">Decision Tree</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# ì˜ˆì œ ë°˜ë³µ ì‹œ ë§ˆë‹¤ ë™ì¼í•œ ì˜ˆì¸¡ ê²°ê³¼ ë„ì¶œì„ ìœ„í•´ random_state ì„¤ì •
dt_clf = DecisionTreeClassifier(random_state=156)
dt_clf.fit(X_train , y_train)
pred = dt_clf.predict(X_test)
accuracy = accuracy_score(y_test , pred)
print('ê²°ì • íŠ¸ë¦¬ ì˜ˆì¸¡ ì •í™•ë„: {0:.4f}'.format(accuracy))

# DecisionTreeClassifierì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
print('DecisionTreeClassifier ê¸°ë³¸ í•˜ì´í¼ íŒŒë¼ë¯¸í„°:\n', dt_clf.get_params())
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767838-0588b0c2-5152-48ba-98aa-ad88ed9b0521.png" alt="image" /></p>

<p>decision tree accuracy ê°’ê³¼ default hyper parameter ê°’ì„ í™•ì¸</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.model_selection import GridSearchCV

params = {
    'max_depth' : [ 6, 8 ,10, 12, 16 ,20, 24]
}

grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )
grid_cv.fit(X_train , y_train)
print('GridSearchCV ìµœê³  í‰ê·  ì •í™•ë„ ìˆ˜ì¹˜:{0:.4f}'.format(grid_cv.best_score_))
print('GridSearchCV ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„°:', grid_cv.best_params_)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767887-a3c4d8a8-5bbb-4f83-9d10-d09b89cc7042.png" alt="image" /></p>

<p>gridsearchCVë¥¼ ì‚¬ìš©í•˜ì—¬ tree depthë¥¼ ë³€í™”</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># GridSearchCVê°ì²´ì˜ cv_results_ ì†ì„±ì„ DataFrameìœ¼ë¡œ ìƒì„±. 
cv_results_df = pd.DataFrame(grid_cv.cv_results_)

# max_depth íŒŒë¼ë¯¸í„° ê°’ê³¼ ê·¸ë•Œì˜ í…ŒìŠ¤íŠ¸(Evaluation)ì…‹, í•™ìŠµ ë°ì´í„° ì…‹ì˜ ì •í™•ë„ ìˆ˜ì¹˜ ì¶”ì¶œ
cv_results_df[['param_max_depth', 'mean_test_score']]
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767928-59fc3521-157b-425e-86fb-5b680b2f0b76.png" alt="image" /></p>

<p>max_depthì˜ ë³€í™”ì— ë”°ë¥¸ í‰ê·  ì •í™•ë„ ìˆ˜ì¹˜ ì¶”ì¶œ</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>max_depths = [ 6, 8 ,10, 12, 16 ,20, 24]
# max_depth ê°’ì„ ë³€í™” ì‹œí‚¤ë©´ì„œ ê·¸ë•Œë§ˆë‹¤ í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ ì…‹ì—ì„œì˜ ì˜ˆì¸¡ ì„±ëŠ¥ ì¸¡ì •
for depth in max_depths:
    dt_clf = DecisionTreeClassifier(max_depth=depth, random_state=156)
    dt_clf.fit(X_train , y_train)
    pred = dt_clf.predict(X_test)
    accuracy = accuracy_score(y_test , pred)
    print('max_depth = {0} ì •í™•ë„: {1:.4f}'.format(depth , accuracy))
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126767975-fc5ce7d0-2838-49d7-8617-18cdb7fa8462.png" alt="image" /></p>

<p>gridsearchCV ì—†ì´ ë³„ë„ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ì—ì„œ depth ë³€í™”</p>

<p>ê¹Šì´ 8ì„ ë„˜ìœ¼ë©´ over fittingì´ ì¼ì–´ë‚˜ëŠ”ê²ƒì„ í™•ì¸.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>params = {
    'max_depth' : [ 8 , 12, 16 ,20], 
    'min_samples_split' : [16,24],
}

grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )
grid_cv.fit(X_train , y_train)
print('GridSearchCV ìµœê³  í‰ê·  ì •í™•ë„ ìˆ˜ì¹˜: {0:.4f}'.format(grid_cv.best_score_))
print('GridSearchCV ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„°:', grid_cv.best_params_)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126768011-7d983335-519a-4a10-b6cd-c8860b931aeb.png" alt="image" /></p>

:ET