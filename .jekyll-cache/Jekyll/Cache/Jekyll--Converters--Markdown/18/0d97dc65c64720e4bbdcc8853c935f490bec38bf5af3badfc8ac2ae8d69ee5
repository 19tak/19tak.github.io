I"×<h1 id="ë¬¸ì œ">ë¬¸ì œ</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('diabetes.csv', sep=',')
print("### About Outcome value ###")
print(df['Outcome'].value_counts())
df.head(3)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126758410-0638c13f-5152-49af-9f28-394dddd2417e.png" alt="image" /></p>

<p><img src="https://user-images.githubusercontent.com/84369912/126758428-62a10c63-0a7f-4f87-8721-f048a51e44be.png" alt="image" /></p>

<p>Outcome Negative( 0 ) ê°’ì´ 500ê°œ, Positive ( 1 ) ê°’ì´ 268ê°œ</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>df.info()
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126758463-28b30f3a-4051-450e-aaa3-e985caffc3f8.png" alt="image" /></p>

<p>Null ì¡´ì¬ í•˜ì§€ ì•ŠìŒì„ í™•ì¸, Data type í™•ì¸</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>df.describe()
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126758729-a631eb8b-9849-48f6-a89d-ed4c09cb18e9.png" alt="image" /></p>

<p>Glucose, BMI, Insulin ë“± min ê°’ì´ 0ì¸ feature í™•ì¸, ë°ì´í„° ëŒ€ì²´ ë° ìŠ¤ì¼€ì¼ë§ ì ìš© ê²€í† </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_clf_eval(y_test=None, pred=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    f1 = f1_score(y_test,pred)
    # ROC-AUC ì¶”ê°€ 
    roc_auc = roc_auc_score(y_test, pred)
    print('ì˜¤ì°¨ í–‰ë ¬')
    print(confusion)
    # ROC-AUC print ì¶”ê°€
    print('ì •í™•ë„: {0:.4f}, ì •ë°€ë„: {1:.4f}, ì¬í˜„ìœ¨: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc),'\n')
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸ X, ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ yë¥¼ ì¶”ì¶œ. 
# ë§¨ ëì´ Outcome ì»¬ëŸ¼ìœ¼ë¡œ ë ˆì´ë¸” ê°’ì„. ì»¬ëŸ¼ ìœ„ì¹˜ -1ì„ ì´ìš©í•´ ì¶”ì¶œ 
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y)

# ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ í•™ìŠµ,ì˜ˆì¸¡ ë° í‰ê°€ ìˆ˜í–‰. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train , y_train)
pred = lr_clf.predict(X_test)
get_clf_eval(y_test , pred)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126758816-c342ae21-9e4c-453f-9920-a59fedf95977.png" alt="image" /></p>

<p>Outcome Negativeê°€ ìƒëŒ€ì ìœ¼ë¡œ ë§ìœ¼ë¯€ë¡œ, ì¬í˜„ìœ¨ ì„±ëŠ¥ í–¥ìƒ ìœ„í•´ ì„ê³—ê°’ ë³„ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ ê°’ì˜ ë³€í™” í™•ì¸</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def precision_recall_curve_plot(y_test=None, pred_proba_c1=None):
    # threshold ndarrayì™€ ì´ thresholdì— ë”°ë¥¸ ì •ë°€ë„, ì¬í˜„ìœ¨ ndarray ì¶”ì¶œ. 
    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)
    
    # Xì¶•ì„ thresholdê°’ìœ¼ë¡œ, Yì¶•ì€ ì •ë°€ë„, ì¬í˜„ìœ¨ ê°’ìœ¼ë¡œ ê°ê° Plot ìˆ˜í–‰. ì •ë°€ë„ëŠ” ì ì„ ìœ¼ë¡œ í‘œì‹œ
    plt.figure(figsize=(8,6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')
    
    # threshold ê°’ X ì¶•ì˜ Scaleì„ 0.1 ë‹¨ìœ„ë¡œ ë³€ê²½
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1),2))
    
    # xì¶•, yì¶• labelê³¼ legend, ê·¸ë¦¬ê³  grid ì„¤ì •
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()
    plt.show()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pred_proba_c1 = lr_clf.predict_proba(X_test)[:, 1]
precision_recall_curve_plot(y_test, pred_proba_c1)
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/84369912/126758990-730e01e9-91e8-4940-b542-bee5a0e14172.png" alt="image" /></p>

<p>ì„ê³„ê°’ ì•½ 0.42ì—ì„œ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ê· í˜•ì´ ë§ì§€ë§Œ
ë‘ ì§€í‘œ ëª¨ë‘ 0.7 ë¯¸ë§Œì´ë¯€ë¡œ ë°ì´í„° ëŒ€ì²´ ë° ìŠ¤ì¼€ì¼ë§ ì ìš©</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>
:ET