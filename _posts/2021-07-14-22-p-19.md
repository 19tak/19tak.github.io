---
layout: post
title: "[19] Python 과제, 피마인디언 당뇨병 예측 "
categories: [Python, KFQ]
tags: [Python, KFQ, sklearn, logistic regression, decision tree, random forest]
fullview: false
comments: false
---

# 문제
## Logistic Regression 으로 진행

```
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('diabetes.csv', sep=',')
print("### About Outcome value ###")
print(df['Outcome'].value_counts())
df.head(3)
```
![image](https://user-images.githubusercontent.com/84369912/126758410-0638c13f-5152-49af-9f28-394dddd2417e.png)

![image](https://user-images.githubusercontent.com/84369912/126758428-62a10c63-0a7f-4f87-8721-f048a51e44be.png)

Outcome Negative( 0 ) 값이 500개, Positive ( 1 ) 값이 268개

```
df.info()
```
![image](https://user-images.githubusercontent.com/84369912/126758463-28b30f3a-4051-450e-aaa3-e985caffc3f8.png)

Null 존재 하지 않음을 확인, Data type 확인

```
df.describe()
```
![image](https://user-images.githubusercontent.com/84369912/126758729-a631eb8b-9849-48f6-a89d-ed4c09cb18e9.png)

Glucose, BMI, Insulin 등 min 값이 0인 feature 확인, 데이터 대체 및 스케일링 적용 검토

```
def get_clf_eval(y_test=None, pred=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    f1 = f1_score(y_test,pred)
    # ROC-AUC 추가 
    roc_auc = roc_auc_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc),'\n')
```

```
# 피처 데이터 세트 X, 레이블 데이터 세트 y를 추출. 
# 맨 끝이 Outcome 컬럼으로 레이블 값임. 컬럼 위치 -1을 이용해 추출 
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y)

# 로지스틱 회귀로 학습,예측 및 평가 수행. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train , y_train)
pred = lr_clf.predict(X_test)
get_clf_eval(y_test , pred)
```
![image](https://user-images.githubusercontent.com/84369912/126758816-c342ae21-9e4c-453f-9920-a59fedf95977.png)

Outcome Negative가 상대적으로 많으므로, 재현율 성능 향상 위해 임곗값 별 정밀도와 재현율 값의 변화 확인

```
def precision_recall_curve_plot(y_test=None, pred_proba_c1=None):
    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. 
    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)
    
    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시
    plt.figure(figsize=(8,6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')
    
    # threshold 값 X 축의 Scale을 0.1 단위로 변경
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1),2))
    
    # x축, y축 label과 legend, 그리고 grid 설정
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()
    plt.show()
```

```
pred_proba_c1 = lr_clf.predict_proba(X_test)[:, 1]
precision_recall_curve_plot(y_test, pred_proba_c1)
```
![image](https://user-images.githubusercontent.com/84369912/126758990-730e01e9-91e8-4940-b542-bee5a0e14172.png)

임계값 약 0.42에서 정밀도와 재현율의 균형이 맞지만
두 지표 모두 0.7 미만이므로 데이터 대체 및 스케일링 적용

```
plt.hist(df['Glucose'], bins=10)
```
![image](https://user-images.githubusercontent.com/84369912/126759041-c694d6a7-3c80-425d-a949-aff0d7dee3eb.png)

Glucose의 히스토그램, min 값 0 존재 추가 확인

```
# 0값을 검사할 피처명 리스트 객체 설정
zero_features = ['Glucose', 'BloodPressure','SkinThickness','Insulin','BMI']

# 전체 데이터 건수
total_count = df['Glucose'].count()

# 피처별로 반복 하면서 데이터 값이 0 인 데이터 건수 추출하고, 퍼센트 계산
for feature in zero_features:
    zero_count = df[df[feature] == 0][feature].count()
    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f} %'.format(feature, zero_count, 100*zero_count/total_count))
```
![image](https://user-images.githubusercontent.com/84369912/126759091-2d0c78a8-43d5-43ea-bd7e-bc899f0cfb96.png)

Pregnancies 를 제외한 min 값이 0인 feature의 데이터 확인

```
# zero_features 리스트 내부에 저장된 개별 피처들에 대해서 0값을 평균 값으로 대체
df[zero_features]=df[zero_features].replace(0, df[zero_features].mean())

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

# StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용
scaler = StandardScaler( )
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 156, stratify=y)

# 로지스틱 회귀로 학습, 예측 및 평가 수행. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train , y_train)
pred = lr_clf.predict(X_test)
get_clf_eval(y_test , pred)
```
![image](https://user-images.githubusercontent.com/84369912/126759163-aa07b5fb-08ab-4ad4-8561-4ecc12700a52.png)

데이터 대체 및 스케일링 적용 후 정확도와 재현율이 올라간것 확인

```
from sklearn.preprocessing import Binarizer

def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):
    # thresholds 리스트 객체내의 값을 차례로 iteration하면서 Evaluation 수행.
    for custom_threshold in thresholds:
        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) 
        custom_predict = binarizer.transform(pred_proba_c1)
        print('임곗값:',custom_threshold)
        get_clf_eval(y_test , custom_predict)
```

```
thresholds = [0.3 , 0.33 ,0.36,0.39, 0.42 , 0.45 ,0.48, 0.50]
pred_proba = lr_clf.predict_proba(X_test)
get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds )
```
![image](https://user-images.githubusercontent.com/84369912/126759221-60b2df99-d091-4df8-be55-731267a074a7.png)

임계값 변화에 대한 성능 수치 변화

```
# 임곗값를 0.48로 설정한 Binarizer 생성
binarizer = Binarizer(threshold=0.48)

# 위에서 구한 lr_clf의 predict_proba() 예측 확률 array에서 1에 해당하는 컬럼값을 Binarizer변환. 
pred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1)) 

get_clf_eval(y_test , pred_th_048)
```
![image](https://user-images.githubusercontent.com/84369912/126759288-75ed71af-be20-4e60-bda9-341f8db3cae7.png)

임계값 0.48에서 전체적인 성능 평가 지표를 유지하며 재현율을 향상시킨다.

## Decision Tree & Random Forest 로 추가진행
```
import numpy as np
import pandas as pd

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.preprocessing import StandardScaler

# 0값을 검사할 피처명 리스트 객체 설정
zero_features = ['Glucose', 'BloodPressure','SkinThickness','Insulin','BMI']

df = pd.read_csv('diabetes.csv', sep=',')

# zero_features 리스트 내부에 저장된 개별 피처들에 대해서 0값을 평균 값으로 대체
df[zero_features]=df[zero_features].replace(0, df[zero_features].mean())

y_df = df.iloc[:,-1]
X_df = df.iloc[:,:-1]

# StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용
scaler = StandardScaler( )
X_scaled = scaler.fit_transform(X_df)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_df, test_size = 0.2, random_state = 156, stratify=y_df)
```

```
# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성
dt_clf = DecisionTreeClassifier(random_state = 156)
rf_clf = RandomForestClassifier(random_state = 156)

# DecisionTreeClassifier 학습/예측/평가
dt_clf.fit(X_train , y_train)
dt_pred = dt_clf.predict(X_test)
print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))

# RandomForestClassifier 학습/예측/평가
rf_clf.fit(X_train , y_train)
rf_pred = rf_clf.predict(X_test)
print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))
```
![image](https://user-images.githubusercontent.com/84369912/126759444-5d52706c-6358-420d-8836-8ac8141f1159.png)

앞선 과정과 동일하게  값이 0인 feature 들의 데이터를 대체하고 Standard Scaling 이후 

Decision Tree 와 Random Forest의 정확도를 확인. Logistic Regression 보다 낮은 정확도를 보인다.

```
from sklearn.model_selection import cross_val_score

scores = cross_val_score(dt_clf, X_df , y_df , cv=5)
for iter_count,accuracy in enumerate(scores):
    print("교차 검증 {0} 정확도: {1:.4f}".format(iter_count, accuracy))

print("평균 정확도: {0:.4f}".format(np.mean(scores)))
```
![image](https://user-images.githubusercontent.com/84369912/126759509-f0cafc91-3686-4e44-9d50-7364cf86f454.png)

Decision Tree 모델에 대한 교차 검증 수행

```
from sklearn.model_selection import GridSearchCV

parameters = {'max_depth':[2,3,5,10],
             'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}

grid_dclf = GridSearchCV(dt_clf , param_grid=parameters , scoring='accuracy' , cv=5)
grid_dclf.fit(X_train , y_train)

print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)
print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))
best_dclf = grid_dclf.best_estimator_

# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. 
dpredictions = best_dclf.predict(X_test)
accuracy = accuracy_score(y_test , dpredictions)
print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))
```
![image](https://user-images.githubusercontent.com/84369912/126759582-264b0c02-45e6-48ce-bfec-232cfd98f1e3.png)

Grid Search CV 를 이용하여 Decision Tree 의 최적 하이퍼 파라미터와 그에 대한 예측 성능 측정