---
layout: post
title: "[04] DeepLearning, 텐서 계산과 그래디언트 기반 최적화"
categories: [AI, DeepLearning]
tags: [AI, DeepLearning, TensorFlow, Keras, Python, Jupyter Notebook]
fullview: false
comments: false
---

본 포스팅은 **"케라스 창시자에게 배우는 딥러닝"** - (길벗출판사, 프랑소와 숄레 지음, 박해선 옮김)을 바탕으로 공부한 내용을 정리한 것입니다.

1. 텐서와 층 예시
    + 배치 데이터
2. 텐서 계산
    + 브로드캐스팅
    + 브로드캐스팅 예시
3. 그래디언트 기반 최적화

---

**[이전 포스팅 1](https://19tak.github.io/posts/02-dl/ "[02] DeepLearning, MNIST 손글씨 숫자 분류 문제")**, 
**[이전 포스팅 2](https://19tak.github.io/posts/03-dl/ "[03] DeepLearning, 활성화 함수")**과 함께 보자.

# 1. 텐서와 층 예시

텐서플로우는 channel-last 방식, 씨아노는 channel-first 방식

- **벡터 데이터:** **(samples, features)** 크기의 **2D 텐서**
    + 나이, 우편번호, 소득으로 구성된 10만명의 인구 통계 데이터셋은 (100000, 3) 크기의 텐서에 저장
    + (단어 2만개로 만든 사전에서) 각 단어가 등장한 횟수로 표현된 500개 문서의 데이터셋은 (500, 20000)
    + 완전 연결 층 (fully connected layer), 밀집 층 (dense layer), 밀집 연결 층 (densley connected layer)
- **시계열, 시퀀스 (sequence) 데이터:** **(samples, timesteps, features)** 크기의 **3D 텐서**
    + 1분마다 현재 주식 가격, 최고와 최소 가격을 저장한 250일 치의 데이터는 (250, 390, 3)
    > 미국 증권 거래소 개장시간 09:30 ~ 16:00로 390분
    + 128개의 알파벳으로 구성된 280개의 문자 시퀀스인 100만개의 트윗 데이터셋은 (1000000, 280, 128)
    + LSTM 같은 순환 층 (recurrent layer)
- **이미지:** **(samples, height, width, channels)** 또는 (samples, channels, height, width) **4D 텐서**
    + 256x256 크기 흑백 이미지에 대한 128개의 배치는 (128, 256, 256, 1)
    + 256x256 크기 컬러 이미지에 대한 128개의 배치는 (128, 256, 256, 3)
    + 2D 합성곱 층 (convolution layer)
- **동영상:** **(samples, frames, height, width, channels)** 또는 (samples, frames, channels, height, width) **5D 텐서**
    + 60초 144x256 비디오를 초당 4프레임 샘플링 (총 240 프레임), 비디오 4개 가진 배치는 (4, 240, 144, 256, 3)

## 배치 데이터

일반적으로 딥러닝에서 사용하는 모든 데이터 텐서의 0번째 축은 **샘플 축, 샘플 차원** (sample axis, dimension)이라 부른다.

딥러닝 모델은 한번엔 전체 데이터셋을 처리하지 않고, 작은 **배치 (batch)**로 나눈다.

배치 데이터를 다룰 때는 0번 축을 **배치 축, 배치 차원** (batch axis, dimension)이라 부른다.

---

# 2. 텐서 계산

## 브로드캐스팅

크기가 다른 두 텐서가 더해질 때, 작은 텐서가 큰 텐서의 크기에 맞추어 브로드캐스팅 (broadcasting)이 된다.

1. 큰 텐서의 ndim에 맞게 작은 텐서에 브로드캐스팅 축이 추가된다.
2. 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다.

## 브로드캐스팅 예시

X의 크기는 (32,10)이고 y는 (10,)이라 할때 y에 비어 있는 첫 번째 축을 추가하여 크기를 (1,10)으로 만든다.

이 y를 이 축에 32번 반복하면 Y의 크기는 (32,10)

구현 입장에서는 새로운 텐서가 만들어지면 비효율적이므로 반복되는 연산은 가상으로, 알고리즘 수준으로 일어난다.

새로운 축을 따라 반복된다고 생각하는 것이 이해하기 쉽다고 한다. 

---

# 3. 그래디언트 기반 최적화



---

# 참고

**"케라스 창시자에게 배우는 딥러닝"** - (길벗출판사, 프랑소와 숄레 지음, 박해선 옮김)

- 깃허브: <http://github.com/gilbutITbook/006975>
- 길벗출판사 홈페이지: <http://www.gilbut.co.kr>
- tensorflow 2.4 버전 코드 <https://github.com/rickiepark/deep-learning-with-python-notebooks/tree/tf2>